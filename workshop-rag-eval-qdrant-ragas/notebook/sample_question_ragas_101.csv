,question,contexts,ground_truth,evolution_type,metadata,episode_done
0,How can audio embeddings be used to develop a music recommendation engine?,"['---\n\ntitle: Examples\n\nweight: 25\n\n# If the index.md file is empty, the link to the section will be hidden from the sidebar\n\nis_empty: false\n\n---\n\n\n\n# Sample Use Cases \n\n\n\nOur Notebooks offer complex instructions that are supported with a throrough explanation. Follow along by trying out the code and get the most out of each example.\n\n\n\n| Example                                                                                                                                                                                                                               | Description                                                                                     | Stack                      |   \n\n|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------|----------------------------|\n\n| [Intro to Semantic Search and Recommendations Systems](https://githubtocolab.com/qdrant/examples/blob/master/qdrant_101_getting_started/getting_started.ipynb)                                                                        | Learn how to get started building semantic search and recommendation systems.                   | Qdrant                     | \n\n| [Search and Recommend Newspaper Articles](https://githubtocolab.com/qdrant/examples/blob/master/qdrant_101_text_data/qdrant_and_text_data.ipynb)                                                                                      | Work with text data to develop a semantic search and a recommendation engine for news articles. | Qdrant                     | \n\n| [Recommendation System for Songs](https://githubtocolab.com/qdrant/examples/blob/master/qdrant_101_audio_data/03_qdrant_101_audio.ipynb)                                                                                              | Use Qdrant to develop a music recommendation engine based on audio embeddings.                  | Qdrant                     | \n\n| [Image Comparison System']",Use Qdrant to develop a music recommendation engine based on audio embeddings.,simple,[{'source': 'documentation/examples.md'}],True
1,What is the purpose of the Qdrant Startup Search demo in utilizing semantic search?,['---\n\ndraft: false\n\ntitle: Startup Search\n\nshort_description: Qdrant Startup Search. This demo uses short descriptions of startups to perform a semantic search\n\ndescription: This demo uses short descriptions of startups to perform a semantic search. Each startup description converted into a vector using a pre-trained SentenceTransformer model and uploaded to the Qdrant vector search engine. Demo service processes text input with the same model and uses its output to query Qdrant for similar vectors. You can turn neural search on and off to compare the result with regular full-text search.\n\npreview_image: /demo/startup_search_demo.jpg\n\nlink: https://qdrant.to/semantic-search-demo\n\nweight: 1\n\nsitemapExclude: True\n\n---\n'],"The purpose of the Qdrant Startup Search demo is to utilize semantic search by converting short descriptions of startups into vectors using a pre-trained SentenceTransformer model and uploading them to the Qdrant vector search engine. The demo service processes text input with the same model and uses its output to query Qdrant for similar vectors, allowing users to compare the results with regular full-text search.",simple,[{'source': 'demo/demo-1.md'}],True
2,What is the Qdrant vector search engine used for in the development of vector search based applications?,['---\n\npage_title: Vector Search Demos and Examples\n\ndescription: Interactive examples and demos of vector search based applications developed with Qdrant vector search engine. \n\ntitle: Vector Search Demos\n\nsection_title: Interactive Live Examples\n\n---'],The Qdrant vector search engine is used in the development of vector search based applications for interactive examples and demos.,simple,[{'source': 'demo/_index.md'}],True
3,How is a SentenceTransformer model used in the Qdrant Startup Search demo?,['---\n\ndraft: false\n\ntitle: Startup Search\n\nshort_description: Qdrant Startup Search. This demo uses short descriptions of startups to perform a semantic search\n\ndescription: This demo uses short descriptions of startups to perform a semantic search. Each startup description converted into a vector using a pre-trained SentenceTransformer model and uploaded to the Qdrant vector search engine. Demo service processes text input with the same model and uses its output to query Qdrant for similar vectors. You can turn neural search on and off to compare the result with regular full-text search.\n\npreview_image: /demo/startup_search_demo.jpg\n\nlink: https://qdrant.to/semantic-search-demo\n\nweight: 1\n\nsitemapExclude: True\n\n---\n'],A SentenceTransformer model is used in the Qdrant Startup Search demo to convert short descriptions of startups into vectors. These vectors are then uploaded to the Qdrant vector search engine. The demo service processes text input with the same model and uses its output to query Qdrant for similar vectors.,simple,[{'source': 'demo/demo-1.md'}],True
4,What determines the order of sections in a list of documentation pages?,"['---\n\n#Delimiter files are used to separate the list of documentation pages into sections.\n\ntitle: ""Getting Started""\n\ntype: delimiter\n\nweight: 8 # Change this weight to change order of sections\n\nsitemapExclude: True\n\n---']",The weight assigned to each section determines the order of sections in a list of documentation pages.,simple,[{'source': 'documentation/0-dl.md'}],True
5,How does Qdrant help in semantic search in Startup Search demo?,['---\n\ndraft: false\n\ntitle: Startup Search\n\nshort_description: Qdrant Startup Search. This demo uses short descriptions of startups to perform a semantic search\n\ndescription: This demo uses short descriptions of startups to perform a semantic search. Each startup description converted into a vector using a pre-trained SentenceTransformer model and uploaded to the Qdrant vector search engine. Demo service processes text input with the same model and uses its output to query Qdrant for similar vectors. You can turn neural search on and off to compare the result with regular full-text search.\n\npreview_image: /demo/startup_search_demo.jpg\n\nlink: https://qdrant.to/semantic-search-demo\n\nweight: 1\n\nsitemapExclude: True\n\n---\n'],Qdrant helps in semantic search in the Startup Search demo by converting short descriptions of startups into vectors using a pre-trained SentenceTransformer model and uploading them to the Qdrant vector search engine. The demo service processes text input with the same model and uses its output to query Qdrant for similar vectors. Users can turn neural search on and off to compare the result with regular full-text search.,reasoning,[{'source': 'demo/demo-1.md'}],True
6,How is the multi-language model in the e-commerce products categorization demo using vector databases?,"['---\n\ndraft: false\n\ntitle: E-commerce products categorization\n\nshort_description: E-commerce products categorization demo from Qdrant vector database\n\ndescription: This demo shows how you can use vector database in e-commerce. Enter the name of the product and the application will understand which category it belongs to, based on the multi-language model. The dots represent clusters of products.\n\npreview_image: /demo/products_categorization_demo.jpg\n\nlink: https://qdrant.to/extreme-classification-demo\n\nweight: 3\n\nsitemapExclude: True\n\n---\n']",The multi-language model in the e-commerce products categorization demo is used to understand which category a product belongs to based on the input name of the product. It utilizes vector databases to represent clusters of products.,reasoning,[{'source': 'demo/demo-3.md'}],True
7,How are client libraries used for vector search in collections and what method adds vectors with data?,"[';\n\n\n\nvar operationInfo = await client.UpsertAsync(\n\n\tcollectionName: ""test_collection"",\n\n\tpoints: new List<PointStruct>\n\n\t{\n\n\t\tnew()\n\n\t\t{\n\n\t\t\tId = 1,\n\n\t\t\tVectors = new float[] { 0.05f, 0.61f, 0.76f, 0.74f },\n\n\t\t\tPayload = { [""city""] = ""Berlin"" }\n\n\t\t},\n\n\t\tnew()\n\n\t\t{\n\n\t\t\tId = 2,\n\n\t\t\tVectors = new float[] { 0.19f, 0.81f, 0.75f, 0.11f },\n\n\t\t\tPayload = { [""city""] = ""London"" }\n\n\t\t},\n\n\t\tnew()\n\n\t\t{\n\n\t\t\tId = 3,\n\n\t\t\tVectors = new float[] { 0.36f, 0.55f, 0.47f, 0.94f },\n\n\t\t\tPayload = { [""city""] = ""Moscow"" }\n\n\t\t},\n\n\t\t// Truncated\n\n\t}\n\n);\n\n\n\nConsole.WriteLine(operationInfo);\n\n```\n\n\n\n**Response:**\n\n\n\n```python\n\noperation_id=0 status=<UpdateStatus.COMPLETED: \'completed\'>\n\n```\n\n\n\n```typescript\n\n{ operation_id: 0, status: \'completed\' }\n\n```\n\n\n\n```rust\n\nPointsOperationResponse {\n\n    result: Some(UpdateResult {\n\n        operation_id: 0,\n\n        status: Completed,\n\n    }),\n\n    time: 0.006347708,\n\n}\n\n```\n\n\n\n```java\n\noperation_id: 0\n\nstatus: Completed\n\n```\n\n\n\n```csharp\n\n{ ""operationId"": ""0"", ""status"": ""Completed"" }\n\n```\n\n\n\n## Run a query\n\n\n\nLet\'s ask a basic question - Which of our stored vectors are most similar to the query vector `[0.2, 0.1, 0.9, 0.7]`?\n\n\n\n```python\n\nsearch_result = client.search(\n\n    collection_name=""test_collection"", query_vector=[0.2, 0.1, 0.9, 0.7], limit=3\n\n)\n\n\n\nprint(search_result)\n\n```\n\n\n\n```typescript\n\nlet searchResult = await client.search(""test_collection"", {\n\n  vector: [0.2, 0.1, 0.9, 0.7],\n\n  limit: 3,\n\n});\n\n\n\nconsole.debug(searchResult);\n\n```\n\n\n\n```rust\n\nuse qdrant_client::qdrant::SearchPoints;\n\n\n\nlet search_result = client\n\n    .search_points(&SearchPoints {\n\n        collection_name: ""test_collection"".to_string(),\n\n        vector: vec![0.2, 0.1, 0.9, 0.7],\n\n        limit: 3,\n\n        with_payload: Some(true.into()),\n\n        ..Default::default()\n\n    })\n\n    .await?;\n\n\n\ndbg!(search_result);\n\n```\n\n\n\n```java\n\nimport java.util.List;\n\n\n\nimport io.qdrant.client.grpc.Points.ScoredPoint;\n\nimport io.qdrant.client.grpc.Points.SearchPoints;\n\n\n\nimport static io.qdrant.client.WithPayloadSelectorFactory.enable;\n\n\n\nList<ScoredPoint> searchResult =\n\n    client\n\n        .searchAsync(\n\n            SearchPoints.newBuilder()\n\n                .setCollectionName(""test_collection"")\n\n                .setLimit(3)\n\n                .addAllVector(List.of(0.2f, 0.1f, 0.9']","Client libraries are used for vector search in collections by providing methods to search for vectors based on similarity to a query vector. The method that adds vectors with data is the 'search' method in the client library, which takes parameters such as the collection name, query vector, and limit to return the most similar vectors.",multi_context,[{'source': 'documentation/quick-start.md'}],True
8,"Which city is associated with ""NY""?","[': ""city""\n\n  value {\n\n    string_value: ""Berlin""\n\n  }\n\n}\n\nscore: 1.273\n\nversion: 1\n\n, id {\n\n  num: 3\n\n}\n\npayload {\n\n  key: ""city""\n\n  value {\n\n    string_value: ""Moscow""\n\n  }\n\n}\n\nscore: 1.208\n\nversion: 1\n\n]\n\n```\n\n\n\n```csharp\n\n[\n\n  {\n\n    ""id"": {\n\n      ""num"": ""4""\n\n    },\n\n    ""payload"": {\n\n      ""city"": {\n\n        ""stringValue"": ""New York""\n\n      }\n\n    },\n\n    ""score"": 1.362,\n\n    ""version"": ""7""\n\n  },\n\n  {\n\n    ""id"": {\n\n      ""num"": ""1""\n\n    },\n\n    ""payload"": {\n\n      ""city"": {\n\n        ""stringValue"": ""Berlin""\n\n      }\n\n    },\n\n    ""score"": 1.273,\n\n    ""version"": ""7""\n\n  },\n\n  {\n\n    ""id"": {\n\n      ""num"": ""3""\n\n    },\n\n    ""payload"": {\n\n      ""city"": {\n\n        ""stringValue"": ""Moscow""\n\n      }\n\n    },\n\n    ""score"": 1.208,\n\n    ""version"": ""7""\n\n  }\n\n]\n\n```\n\n\n\nThe results are returned in decreasing similarity order. Note that payload and vector data is missing in these results by default.\n\nSee [payload and vector in the result](../concepts/search#payload-and-vector-in-the-result) on how to enable it.\n\n\n\n## Add a filter\n\n\n\nWe can narrow down the results further by filtering by payload. Let\'s find the closest results that include ""London"".\n\n\n\n```python\n\nfrom qdrant_client.http.models import Filter, FieldCondition, MatchValue\n\n\n\nsearch_result = client.search(\n\n    collection_name=""test_collection"",\n\n    query_vector=[0.2, 0.1, 0.9, 0.7],\n\n    query_filter=Filter(\n\n        must=[FieldCondition(key=""city"", match=MatchValue(value=""London""))]\n\n    ),\n\n    with_payload=True,\n\n    limit=3,\n\n)\n\n\n\nprint(search_result)\n\n```\n\n\n\n```typescript\n\nsearchResult = await client.search(""test_collection"", {\n\n  vector: [0.2, 0.1, 0.9, 0.7],\n\n  filter: {\n\n    must: [{ key: ""city"", match: { value: ""London"" } }],\n\n  },\n\n  with_payload: true,\n\n  limit: 3,\n\n});\n\n\n\nconsole.debug(searchResult);\n\n```\n\n\n\n```rust\n\nuse qdrant_client::qdrant::{Condition, Filter, SearchPoints};\n\n\n\nlet search_result = client\n\n    .search_points(&SearchPoints {\n\n        collection_name: ""test_collection"".to_string(),\n\n        vector: vec![0.2, 0.1, 0.9, 0.7],\n\n        filter: Some(Filter::all([Condition::matches(\n\n            ""city"",\n\n            ""London"".to_string(),\n\n        )])),\n\n        limit: 2,\n\n        ..Default::default()\n\n    })\n\n    .await?;\n\n\n\ndbg!(search_result);\n\n```\n\n\n\n```java\n\nimport static io.qdrant.client.ConditionFactory.matchKeyword;\n\n\n\nList<ScoredPoint> searchResult', ' =\n\n    client\n\n        .searchAsync(\n\n            SearchPoints.newBuilder()\n\n                .setCollectionName(""test_collection"")\n\n                .setLimit(3)\n\n                .setFilter(Filter.newBuilder().addMust(matchKeyword(""city"", ""London"")))\n\n                .addAllVector(List.of(0.2f, 0.1f, 0.9f, 0.7f))\n\n                .setWithPayload(enable(true))\n\n                .build())\n\n        .get();\n\n\n\nSystem.out.println(searchResult);\n\n```\n\n\n\n```csharp\n\nusing static Qdrant.Client.Grpc.Conditions;\n\n\n\nvar searchResult = await client.SearchAsync(\n\n\tcollectionName: ""test_collection"",\n\n\tvector: new float[] { 0.2f, 0.1f, 0.9f, 0.7f },\n\n\tfilter: MatchKeyword(""city"", ""London""),\n\n\tlimit: 3,\n\n\tpayloadSelector: true\n\n);  \n\n\n\nConsole.WriteLine(searchResult);\n\n```\n\n\n\n**Response:**\n\n\n\n```python\n\nScoredPoint(id=2, version=0, score=0.871, payload={""city"": ""London""}, vector=None)\n\n```\n\n\n\n```typescript\n\n[\n\n  {\n\n    id: 2,\n\n    version: 0,\n\n    score: 0.871,\n\n    payload: { city: ""London"" },\n\n    vector: null,\n\n  },\n\n];\n\n```\n\n\n\n```rust\n\nSearchResponse {\n\n    result: [\n\n        ScoredPoint {\n\n            id: Some(\n\n                PointId {\n\n                    point_id_options: Some(\n\n                        Num(\n\n                            2,\n\n                        ),\n\n                    ),\n\n                },\n\n            ),\n\n            payload: {\n\n                ""city"": Value {\n\n                    kind: Some(\n\n                        StringValue(\n\n                            ""London"",\n\n                        ),\n\n                    ),\n\n                },\n\n            },\n\n            score: 0.871,\n\n            version: 0,\n\n            vectors: None,\n\n        },\n\n    ],\n\n    time: 0.004001083,\n\n}\n\n```\n\n\n\n```java\n\n[id {\n\n  num: 2\n\n}\n\npayload {\n\n  key: ""city""\n\n  value {\n\n   ']",nan,multi_context,"[{'source': 'documentation/quick-start.md'}, {'source': 'documentation/quick-start.md'}]",True
9,What feature in the Food Discovery Demo suggests similar meals based on appearance and its connection to the Startup Search Demo's semantic search?,"[""---\n\ndraft: false\n\ntitle: Food Discovery\n\nshort_description: Qdrant Food Discovery Demo recommends more similar meals based on how they look\n\ndescription: This demo uses data from Delivery Service. Users may like or dislike the photo of a dish, and the app will recommend more similar meals based on how they look. It's also possible to choose to view results from the restaurants within the delivery radius.\n\npreview_image: /demo/food-discovery-demo.png\n\nlink: https://food-discovery.qdrant.tech/\n\nweight: 2\n\nsitemapExclude: True\n\n---\n""]",The Food Discovery Demo recommends more similar meals based on how they look.,multi_context,[{'source': 'demo/demo-2.md'}],True
